---
title: "UK - Decision Tree"
author: "Author_Name"
date: "5/20/2021"
output: html_document
---

### Load packages
```{r message=FALSE}
my_pack <- function(package)
  {
  new_packages <- package[!(package %in% installed.packages()[, "Package"])]
  if (length(new_packages)) 
    install.packages(new_packages, dependencies = T)
  sapply(package, require, character.only = T)
}

packages <- c("tidyr", "dplyr", "knitr","randomForest","tibble",  "plotROC", "corrplot",
              "fastDummies", "plotly", "FactoMineR","ggplot2", "factoextra",
              "rpart", "rpart.plot",  "caret", "kernlab", "gridExtra")
my_pack(packages)
```


###Load the 'cleaned' file
                                                                       
```{r}
accidents_data <- read.csv (file.choose(), header = TRUE)
accidents_data <- as_tibble(accidents_data[ , !(colnames(accidents_data) %in% c('Accident_Index', 'Latitude',
                                                                             'Datetime','Longitude'))])
```

###Sampling the data to just 20000 observations                                                                       
```{r}
set.seed(1235)
sampled_categorical <- sample_n(accidents_data, 20000)
```

###splitting the data into 70-30, where training-70 and test-30.                                                                       
```{r}
set.seed(2355)
sample_data <- createDataPartition(sampled_categorical$Accident_Severity, list=F, p=0.7) 
train_sample_categorical <- sampled_categorical[sample_data, ]
test_sample_categorical <- sampled_categorical[-sample_data, ]
```

#### Baseline Accuracy                                                                       
```{r}
base_accuracy <- round(length(test_sample_categorical[test_sample_categorical$Accident_Severity=='Slight',]$Accident_Severity)/length(test_sample_categorical$Accident_Severity), 3)
base_accuracy
```
## Training
### Decision Tree
#### Training the unpruned and post-pruned models
```{r}

options(warn=-1)

start_time <- Sys.time()

Upruned_decisiontree <- rpart(Accident_Severity ~ ., data = train_sample_categorical,
                               minbucket=1, method="class", control=rpart.control(cp=0.0001), minsplit=1)
```


#### Unpruned Decision tree                                                                     
```{r}
png("Unpruned DecisionTree1.png", width=1910, height=1075, res=450)

rpart.plot(Upruned_decisiontree, main = "Unpruned - Road accident severity in UK",
           branch.lty=3, extra=104, type=3, split.cex=1.2)
```


#### Unpruned accuracy                                                                   
```{r}
dev.off()
test_sample_categorical$pred <- predict(Upruned_decisiontree, test_sample_categorical, type="class")
end_time <- Sys.time()
df_runtime <- round(as.numeric(end_time - start_time)/60, 2)

####Unpruned accuracy 
unpruned_accuracy <- round(mean(test_sample_categorical$pred==test_sample_categorical$Accident_Severity),3)
unpruned_accuracy
```

####  Decision tree before Pruning                                                               
```{r}
c_p <- as_tibble(Upruned_decisiontree$cptable) %>%
  filter(xerror == max(xerror)) %>%
  filter(xerror <= min(xerror) + xstd) %>%
  select(CP) %>%
  unlist()
prun_decisiontree <- prune(Upruned_decisiontree, cp=c_p)
rpart.plot(prun_decisiontree, main="Pruned - Road accident severity in UK",
           split.cex=1.2, extra=104,branch.lty=3,  type=3)
```

##### Pruned_Tree Accuracy                                                                       
```{r}

test_sample_categorical$pred <- predict(prune_decisiontree, test_sample_categorical, type="class")
pruned_accuracy <- round(mean(test_sample_categorical$pred == test_sample_categorical$Accident_Severity), 3)

#compare accuracy
data.frame(base_accuracy, unpruned_accuracy, pruned_accuracy)


str(test_sample_categorical)
test_sample_categorical$Accident_Severity = as.factor(test_sample_categorical$Accident_Severity)

df_confusion_mtrx <- confusionMatrix(data=test_sample_categorical$pred, reference=test_sample_categorical$Accident_Severity)
test_sample_categorical <- test_sample_categorical %>%
  mutate(pred = predict(prune_decisiontree, type="class", test_sample_categorical),
         pred_prob = predict(prun_decisiontree, type="prob", test_sample_categorical)[,2],
         error = ifelse(pred != Accident_Severity, 1, 0))
```

                                                                       
```{r}
roc <- test_sample_categorical %>%
  select(Accident_Severity, pred_prob) %>%
  mutate(Accident_Severity = as.numeric(Accident_Severity) - 1,
         Accident_Severity.str = c("Fatal_Serious", "Slight")[Accident_Severity + 1]) %>%
  ggplot(aes(d = Accident_Severity, m = pred_prob)) +
  geom_roc(labels = FALSE)
roc +
  style_roc(theme = theme_bw, xlab = "False Positive Rate", ylab = "True Positive Rate") +
  theme(panel.grid.major = element_blank(), panel.border = element_blank(),
        axis.line = element_line(colour = "grey")) +
  ggtitle("Decision Tree - ROC Curve") +
  annotate("text", x = .75, y = .25,
           label = paste("AUROC =", round(calc_auc(roc)$AUC, 3)))
```


```{r}
df_recall <- round(df_conf_mtrx$byClass['Sensitivity'], 3)

df_accuracy <- round(df_conf_mtrx$overall['Accuracy'], 3)

df_precision <- round(df_conf_mtrx$byClass['Pos Pred Value'], 3)

df_roc <- round(calc_auc(roc)$AUC, 3)

df_f1_score <- round(2*((df_precision * df_recall) / (df_precision + df_recall)), 3)

test_sample_categorical <- test_sample_categorical[ , !(names(test_sample_categorical) %in% c('pred', 'pred_prob', 'error'))]

data.frame(base_accuracy, df_accuracy, df_precision, df_recall, df_f1_score, df_roc)
```

### Importance Variable in Decision Tree 
```{r}

df_imp <- data.frame(Variables=names(prun_decisiontree$variable.importance),
                            Variables_Importance=prun_decisiontree$variable.importance)
df_imp_plot <- ggplot(data = df_imp, aes(x=reorder(Variables, fill=Variables_Importance,
                                                   Variables_Importance), y=Variables_Importance)) +
  geom_bar(stat = 'identity') +  labs(x="") +coord_flip() + + theme(legend.position="none")
  + theme(plot.title=element_text(hjust=0.4)) + ggtitle('Decision Tree model Variable Importance')
df_imp_plot

rm(df_imp, c_p )
```
