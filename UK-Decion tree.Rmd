---
title: "UK - Decision Tree"
author: "Vikram"
date: "5/20/2021"
output: html_document
---

###load package
```{r message=FALSE}
my_pack <- function(package){
  new_package <- package[!(package %in% installed.packages()[, "Package"])]
  if (length(new_package)) 
    install.packages(new_package, dependencies = TRUE)
  sapply(package, require, character.only = TRUE)
}

packages <- c("dplyr", "tidyr", "knitr","randomForest","tibble",  "plotROC", "corrplot",
              "fastDummies", "plotly", "FactoMineR","ggplot2", "factoextra",
              "rpart", "rpart.plot",  "caret", "kernlab", "gridExtra")
my_pack(packages)
```


###Load the 'cleaned' file
                                                                       
```{r}
accidents_data <- read.csv (file.choose(), header = TRUE)
accidents_data <- as_tibble(accidents_data[ , !(names(accidents_data) %in% c('Accident_Index', 'Latitude',
                                                                             'Datetime','Longitude'))])
```

###Sampling the data to just 20000 observations                                                                       
```{r}
set.seed(1235)
sampled_df_categorical <- sample_n(accidents_data, 20000)
```

###splitting the data into 70-30, where training-70 and test-30.                                                                       
```{r}
set.seed(2345)
sample <- createDataPartition(sampled_df_categorical$Accident_Severity, p=0.7, list=FALSE) 
train_sample_categorical <- sampled_df_categorical[sample, ]
test_sample_categorical <- sampled_df_categorical[-sample, ]
```

#### Accuracy Baseline                                                                      
```{r}
accuracy_baseline <- round(length(test_sample_categorical[test_sample_categorical$Accident_Severity == 'Slight', ]$Accident_Severity)/
                             length(test_sample_categorical$Accident_Severity), 3)
accuracy_baseline
```
## Training
### Decision Tree
#### Training the unpruned and post-pruned models
```{r}

options(warn=-1)

start_time <- Sys.time()

unpruned_decisiontree <- rpart(Accident_Severity~., data=train_sample_categorical, method="class", 
                               minbucket=1, minsplit=1, control=rpart.control(cp=0.0001))
```


#### Unpruned Decision tree                                                                     
```{r}
png("Unpruned DecisionTree1.png", width=1920, height=1080, res=400)

rpart.plot(unpruned_decisiontree, main="Unpruned - Road accident severity in UK",
           extra=104, branch.lty=3, split.cex=1.2, type=3)
```


#### Unpruned accuracy                                                                   
```{r}
dev.off()
test_sample_categorical$pred <- predict(unpruned_decisiontree, test_sample_categorical, type="class")
end_time <- Sys.time()
dt_runtime <- round(as.numeric(end_time - start_time)/60, 2)

#unpruned accuracy 
unpruned_accuracy <- round(mean(test_sample_categorical$pred == test_sample_categorical$Accident_Severity), 3)
unpruned_accuracy
```

#### Post-pruned Decision tree                                                                       
```{r}
cp <- as_tibble(unpruned_decisiontree$cptable) %>%
  filter(xerror <= min(xerror) + xstd) %>%
  filter(xerror == max(xerror)) %>%
  select(CP) %>%
  unlist()
pruned_decisiontree <- prune(unpruned_decisiontree, cp=cp)
rpart.plot(pruned_decisiontree, main="Pruned - Road accident severity in UK",
           extra=104, split.cex=1.2, branch.lty=3,  type=3)
```

##### Accuracy of pruned tree                                                                       
```{r}

test_sample_categorical$pred <- predict(pruned_decisiontree, test_sample_categorical, type="class")
pruned_accuracy <- round(mean(test_sample_categorical$pred == test_sample_categorical$Accident_Severity), 3)

#compare accuracy
data.frame(accuracy_baseline, unpruned_accuracy, pruned_accuracy)


str(test_sample_categorical)
test_sample_categorical$Accident_Severity = as.factor(test_sample_categorical$Accident_Severity)

dt_confusion_mtrx <- confusionMatrix(data=test_sample_categorical$pred, reference=test_sample_categorical$Accident_Severity)
test_sample_categorical <- test_sample_categorical %>%
  mutate(pred = predict(pruned_decisiontree, type="class", test_sample_categorical),
         pred_prob = predict(pruned_decisiontree, type="prob", test_sample_categorical)[,2],
         error = ifelse(pred != Accident_Severity, 1, 0))
```

                                                                       
```{r}
roc <- test_sample_categorical %>%
  select(Accident_Severity, pred_prob) %>%
  mutate(Accident_Severity = as.numeric(Accident_Severity) - 1,
         Accident_Severity.str = c("Fatal_Serious", "Slight")[Accident_Severity + 1]) %>%
  ggplot(aes(d = Accident_Severity, m = pred_prob)) +
  geom_roc(labels = FALSE)
roc +
  style_roc(theme = theme_bw, xlab = "False Positive Rate", ylab = "True Positive Rate") +
  theme(panel.grid.major = element_blank(), panel.border = element_blank(),
        axis.line = element_line(colour = "grey")) +
  ggtitle("Decision Tree - ROC Curve") +
  annotate("text", x = .75, y = .25,
           label = paste("AUROC =", round(calc_auc(roc)$AUC, 3)))
```


```{r}
dt_recall <- round(dt_confusion_mtrx$byClass['Sensitivity'], 3)

dt_accuracy <- round(dt_confusion_mtrx$overall['Accuracy'], 3)

dt_precision <- round(dt_confusion_mtrx$byClass['Pos Pred Value'], 3)

dt_roc <- round(calc_auc(roc)$AUC, 3)

dt_f1_score <- round(2*((dt_precision * dt_recall) / (dt_precision + dt_recall)), 3)

test_sample_categorical <- test_sample_categorical[ , !(names(test_sample_categorical) %in% c('pred', 'pred_prob', 'error'))]

data.frame(accuracy_baseline, dt_accuracy, dt_precision, dt_recall, dt_f1_score, dt_roc)
```

### Importance Variable in Decision Tree 
```{r}

dt_importance <- data.frame(Variables=names(pruned_decisiontree$variable.importance),
                            Variables_Importance=pruned_decisiontree$variable.importance)
dt_importance_plot <- ggplot(dt_importance, aes(x=reorder(Variables, Variables_Importance), y=Variables_Importance, fill=Variables_Importance)) +
  geom_bar(stat='identity') + coord_flip() + theme(legend.position="none") + labs(x="") +
  ggtitle('Variable Importance in the Decision Tree model') + theme(plot.title = element_text(hjust=0.4))
dt_importance_plot

rm(dt_importance, cp )
```
